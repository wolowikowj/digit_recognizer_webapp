{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\jwolowikow\\Documents\\Entwicklung\\Eigene Projekte\\digit_recognizer_webapp\\.venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(X, y), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size = 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Reshape((28, 28, 1), input_shape=(1, 28, 28)), # reshape, conv2d expects 4 dims - batch size, height, width, and channels\n",
    "    \n",
    "    # Data Augmentation\n",
    "    layers.RandomContrast(factor=0.1),\n",
    "    layers.RandomWidth(factor=0.15), # horizontal stretch\n",
    "    layers.RandomHeight(factor=0.15), # horizontal stretch\n",
    "\n",
    "    # Block One\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(filters=64, kernel_size=4, activation='relu', padding='same'),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    # Block Two\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(filters=128, kernel_size=4, activation='relu', padding='same'),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    # Block Three\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.Conv2D(filters=256, kernel_size=3, activation='relu', padding='same'),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    # Global Average Pooling to ensure the right size even though I stretch the images for data augmentation\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "\n",
    "    # Head\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (45000, 28, 28)\n",
      "Reshaped shape: (45000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "X_train_reshaped = np.expand_dims(X_train, axis=1)\n",
    "X_valid_reshaped = np.expand_dims(X_valid, axis=1)\n",
    "\n",
    "# Check the shape of the reshaped data\n",
    "print(\"Original shape:\", X_train.shape)\n",
    "print(\"Reshaped shape:\", X_train_reshaped.shape)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train_onehot = to_categorical(y_train, num_classes=10)\n",
    "y_valid_onehot = to_categorical(y_valid, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1407/1407 [==============================] - 120s 84ms/step - loss: 0.0188 - categorical_accuracy: 0.9940 - val_loss: 0.0347 - val_categorical_accuracy: 0.9911\n",
      "Epoch 2/10\n",
      "1407/1407 [==============================] - 120s 85ms/step - loss: 0.0200 - categorical_accuracy: 0.9940 - val_loss: 0.0466 - val_categorical_accuracy: 0.9869\n",
      "Epoch 3/10\n",
      "1407/1407 [==============================] - 123s 87ms/step - loss: 0.0193 - categorical_accuracy: 0.9938 - val_loss: 0.0387 - val_categorical_accuracy: 0.9896\n",
      "Epoch 4/10\n",
      "1407/1407 [==============================] - 114s 81ms/step - loss: 0.0191 - categorical_accuracy: 0.9938 - val_loss: 0.0296 - val_categorical_accuracy: 0.9923\n",
      "Epoch 5/10\n",
      "1407/1407 [==============================] - 113s 80ms/step - loss: 0.0151 - categorical_accuracy: 0.9953 - val_loss: 0.0696 - val_categorical_accuracy: 0.9790\n",
      "Epoch 6/10\n",
      "1407/1407 [==============================] - 111s 79ms/step - loss: 0.0149 - categorical_accuracy: 0.9952 - val_loss: 0.0375 - val_categorical_accuracy: 0.9898\n",
      "Epoch 7/10\n",
      "1407/1407 [==============================] - 113s 80ms/step - loss: 0.0126 - categorical_accuracy: 0.9958 - val_loss: 0.0319 - val_categorical_accuracy: 0.9915\n",
      "Epoch 8/10\n",
      "1407/1407 [==============================] - 2179s 2s/step - loss: 0.0126 - categorical_accuracy: 0.9958 - val_loss: 0.0324 - val_categorical_accuracy: 0.9913\n",
      "Epoch 9/10\n",
      "1407/1407 [==============================] - 127s 90ms/step - loss: 0.0136 - categorical_accuracy: 0.9960 - val_loss: 0.0290 - val_categorical_accuracy: 0.9925\n",
      "Epoch 10/10\n",
      "1407/1407 [==============================] - 140s 99ms/step - loss: 0.0115 - categorical_accuracy: 0.9963 - val_loss: 0.0252 - val_categorical_accuracy: 0.9936\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(13)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(epsilon=0.01)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['categorical_accuracy'],\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_reshaped, y_train_onehot,\n",
    "    validation_data=(X_valid_reshaped, y_valid_onehot),\n",
    "    epochs=10,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(filepath='digit_recognizer_v4.keras', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape_6 (Reshape)         (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " random_contrast_6 (RandomC  (None, 28, 28, 1)         0         \n",
      " ontrast)                                                        \n",
      "                                                                 \n",
      " random_width_3 (RandomWidt  (None, 28, None, 1)       0         \n",
      " h)                                                              \n",
      "                                                                 \n",
      " random_height_2 (RandomHei  (None, None, None, 1)     0         \n",
      " ght)                                                            \n",
      "                                                                 \n",
      " batch_normalization_22 (Ba  (None, None, None, 1)     4         \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, None, None, 64)    1088      \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPooli  (None, None, None, 64)    0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_23 (Ba  (None, None, None, 64)    256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, None, None, 128)   131200    \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPooli  (None, None, None, 128)   0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_24 (Ba  (None, None, None, 128)   512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, None, None, 256)   295168    \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPooli  (None, None, None, 256)   0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 256)               0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " batch_normalization_25 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1053518 (4.02 MB)\n",
      "Trainable params: 1052620 (4.02 MB)\n",
      "Non-trainable params: 898 (3.51 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[ 0.11564885,  0.02600539,  0.09970675, ..., -0.01797443,\n",
       "            0.02800392,  0.0551691 ]],\n",
       " \n",
       "         [[ 0.11238336, -0.07653046, -0.06090117, ..., -0.01966076,\n",
       "            0.04341546,  0.01843319]],\n",
       " \n",
       "         [[ 0.01580799, -0.12005648, -0.09421268, ...,  0.06342409,\n",
       "           -0.00283749, -0.15327306]],\n",
       " \n",
       "         [[ 0.04153848, -0.01949162, -0.06791283, ...,  0.09489478,\n",
       "           -0.18114552, -0.02198829]]],\n",
       " \n",
       " \n",
       "        [[[ 0.08800013,  0.06704008,  0.11405012, ...,  0.0847474 ,\n",
       "           -0.0343635 , -0.1424339 ]],\n",
       " \n",
       "         [[ 0.00105619,  0.07189589,  0.01821665, ..., -0.13653323,\n",
       "            0.03820055, -0.10021404]],\n",
       " \n",
       "         [[ 0.00627409, -0.00620933,  0.04072127, ..., -0.03523374,\n",
       "            0.10296713,  0.00581452]],\n",
       " \n",
       "         [[ 0.00887623,  0.01513308, -0.0677743 , ...,  0.07849891,\n",
       "            0.04091445, -0.03638228]]],\n",
       " \n",
       " \n",
       "        [[[ 0.06463675,  0.00224594,  0.07448477, ..., -0.01204129,\n",
       "           -0.12868401, -0.03332275]],\n",
       " \n",
       "         [[-0.03943839,  0.11037563,  0.04233792, ..., -0.02372995,\n",
       "           -0.14207768,  0.05583249]],\n",
       " \n",
       "         [[-0.06051973,  0.08945385, -0.08739053, ..., -0.23554376,\n",
       "           -0.05475912, -0.02221312]],\n",
       " \n",
       "         [[-0.04498428,  0.09817338, -0.00874382, ...,  0.08905894,\n",
       "            0.00831029,  0.12584598]]],\n",
       " \n",
       " \n",
       "        [[[-0.1331736 ,  0.03114446,  0.11802348, ...,  0.13384628,\n",
       "           -0.04871391,  0.01474567]],\n",
       " \n",
       "         [[-0.12272211, -0.01283319,  0.07567468, ...,  0.03380397,\n",
       "           -0.01043894,  0.03322772]],\n",
       " \n",
       "         [[-0.05092095,  0.06903462,  0.02278051, ..., -0.15455538,\n",
       "           -0.0891481 ,  0.12299054]],\n",
       " \n",
       "         [[-0.00283243,  0.03676002, -0.0913794 , ...,  0.03908228,\n",
       "            0.02039261,  0.02941828]]]], dtype=float32),\n",
       " array([-0.02142658, -0.13013549, -0.12310768,  0.0052574 , -0.06573344,\n",
       "         0.01933319, -0.15655123, -0.03778574, -0.02963106, -0.02722038,\n",
       "        -0.11651387, -0.10534141, -0.03360236,  0.03190783, -0.09642681,\n",
       "         0.0283991 , -0.02316301, -0.07143284, -0.07150193, -0.09225111,\n",
       "        -0.04543481, -0.09186581, -0.11946074, -0.0578194 , -0.03582216,\n",
       "         0.02906914, -0.07086737,  0.0035712 , -0.03465222, -0.0347577 ,\n",
       "        -0.07793248, -0.03116911, -0.06383275, -0.03580379, -0.04168375,\n",
       "        -0.06166133, -0.09134042, -0.05421719, -0.00295513,  0.06615143,\n",
       "        -0.11031649, -0.0286095 , -0.01923391,  0.05288521,  0.00078099,\n",
       "        -0.00385168, -0.01535678, -0.07463948, -0.13341706, -0.06599934,\n",
       "        -0.0408627 , -0.08282248, -0.0872511 , -0.02204195, -0.0700807 ,\n",
       "        -0.06387842, -0.05056442, -0.04545029, -0.05494819, -0.08008269,\n",
       "         0.04220761, -0.04863257, -0.15615185, -0.01359081], dtype=float32)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[5].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m filters \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(filters\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]):\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "filters = model.layers[6].get_weights()[0]\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(filters.shape[-2]):\n",
    "    plt.subplot(8, 8, i + 1)\n",
    "    plt.imshow(filters[:, :, 0, i], cmap='gray')  # Assuming the filters are grayscale\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
